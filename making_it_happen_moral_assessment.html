<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>OMA: Making It Happen: Moral Assessment</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1> <a href="index.html" style="color: #fff;">OMA</a></h1>
        <h2>Open Moral Agent</h2>
        <a href="https://github.com/EliEhrman/OMA" class="button"><small>View project on</small> GitHub</a>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">

<h3>
<a id="Moral Assessment" class="anchor" href="#Moral Assessment" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Moral Assessment</h3>
<p> 
Consider the list of functional processing activities presented as requirements for language competence. There are some items that may be added to this list. The text tells us that A did an action. We now wish to start asking questions such as: was that action “good”, “bad” or “devoid of ethical content”?<br><br> 
The program may be doing no more than adding a string of words: “A was wrong to do what he did”. One could argue that the computer does not “understand” the judgment any more than it understood the act being judged. However, that criticism is immaterial to the current purposes. The fact is that it is not that difficult to imagine, even with today’s technology, what is required to add that string of words that forms the judgment. Moreover, it will be shown that the string, even in its current form, is actually morally significant.<br><br> 
How would it be done? Well, a start can be made by say, requiring that a moral judgment be passed in the negative every time the phrase “A killed B” is encountered. Of course that would be both incomplete and sometime wrong. We need more natural language processing (NLP) than that. We could have some processing that knows that “A shot B” has a typical result of “B is dead” and that there is a logical implication which should be followed through on that therefore “A shot B” means “A killed B” and that therefore this too is “bad”. <br><br> 
Moreover, one can add more rules such as “A is bad to kill B unless that is the only way to prevent B killing C”. Of course, to effect this judgment some of the more advanced language processing requirements must be available. Extra processing may require that say that if B is chasing C with a loaded gun and taking a couple of shots at C, that means that B is trying to kill C. The program must also know that “killing B is a good way to prevent B from killing C”. However, these requirements were already mentioned.<br><br> 
One important point to note here is that the ability to make any but the most trivial moral judgements depends on the ability to process natural language as described in the list earlier. Even if the program is not fully competent in all the items of the list, it must be at least partially so.<br><br> 

        </section>

        <aside id="sidebar">
 
          <p class="repo-owner"><a href="https://github.com/EliEhrman/OMA"></a>This site is maintained by <a href="https://github.com/EliEhrman">EliEhrman</a>.</p>

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the Architect theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.</p>
        </aside>
      </div>
    </div>

  
  </body>
</html>
